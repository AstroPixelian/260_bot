"""
Persistence service for saving account registration results to CSV files.

Provides safe, reliable CSV persistence with:
- Pandas DataFrame for efficient CSV operations
- File locking to prevent concurrent access issues
- Signal handling for graceful shutdown on Ctrl-C
- Batch saving (configurable batch_size, default 5)
- Append-only operations to prevent data loss
"""

import atexit
import signal
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

import pandas as pd
from filelock import FileLock

from ..models.account import Account


class PersistenceService:
    """Service for persisting account registration results to CSV files"""
    
    def __init__(self, output_dir: str = ".", batch_size: int = 5):
        """
        Initialize persistence service
        
        Args:
            output_dir: Directory to save CSV files (default: current directory)
            batch_size: Number of results to buffer before auto-save (default: 5)
        """
        self.output_dir = Path(output_dir)
        self.batch_size = batch_size
        
        # Generate timestamp-based filename to avoid conflicts
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_id = timestamp
        self.csv_file = self.output_dir / f"registration_results_{timestamp}.csv"
        self.lock_file = self.output_dir / f"registration_results_{timestamp}.csv.lock"
        
        # ä½¿ç”¨pandas DataFrameä½œä¸ºå†…å­˜ç¼“å†²åŒº
        self.buffer_df = pd.DataFrame()
        
        # åˆ›å»ºæ–‡ä»¶é”
        self.file_lock = FileLock(self.lock_file)
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        self._setup_signal_handlers()
        
        # æ³¨å†Œç¨‹åºæ­£å¸¸é€€å‡ºæ—¶çš„æ¸…ç†
        atexit.register(self.force_save)
        
        print(f"ðŸ’¾ ç»“æžœå°†ä¿å­˜åˆ°: {self.csv_file}")
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def emergency_save(signum=None, frame=None):
            print(f"\nðŸš¨ æŽ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ç´§æ€¥ä¿å­˜...")
            success = self.force_save()
            if success:
                print("âœ… æ•°æ®ä¿å­˜å®Œæˆï¼Œç¨‹åºå®‰å…¨é€€å‡º")
            else:
                print("âš ï¸ ä¿å­˜å¯èƒ½ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶")
            sys.exit(0)
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, emergency_save)   # Ctrl-C
        signal.signal(signal.SIGTERM, emergency_save)  # ç¨‹åºç»ˆæ­¢
    
    def add_result(self, account: Account, duration: float, backend: str):
        """æ·»åŠ æ³¨å†Œç»“æžœåˆ°ç¼“å†²åŒº"""
        # åˆ›å»ºæ–°è®°å½•
        new_record = {
            'timestamp': datetime.now().isoformat(),
            'username': account.username,
            'password': account.password,
            'status': account.status.value,
            'notes': account.notes,
            'duration_seconds': round(duration, 2),
            'backend': backend,
            'session_id': self.session_id
        }
        
        # æ·»åŠ åˆ°DataFrameç¼“å†²åŒº
        new_df = pd.DataFrame([new_record])
        self.buffer_df = pd.concat([self.buffer_df, new_df], ignore_index=True)
        
        print(f"ðŸ“ ç¼“å†²åŒº: {len(self.buffer_df)}/{self.batch_size}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡ä¿å­˜
        if len(self.buffer_df) >= self.batch_size:
            self.force_save()
        else:
            # å¦‚æžœæ²¡æœ‰è¾¾åˆ°batch_sizeï¼Œç«‹å³ä¿å­˜å•æ¡è®°å½•é˜²æ­¢æ•°æ®ä¸¢å¤±
            # ä½†ä¿å­˜åŽä¸æ¸…ç©ºç¼“å†²åŒºï¼Œè¿™æ ·atexitæ—¶å°±ä¸ä¼šé‡å¤ä¿å­˜
            self._save_single_record_immediate(new_record)
    
    def _save_single_record_immediate(self, record: Dict[str, Any]):
        """ç«‹å³ä¿å­˜å•æ¡è®°å½•ï¼ˆé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼‰ï¼Œå¹¶æ ‡è®°å·²ä¿å­˜"""
        try:
            single_df = pd.DataFrame([record])
            with self.file_lock:
                single_df.to_csv(
                    self.csv_file,
                    mode='a',
                    header=not self.csv_file.exists(),
                    index=False,
                    encoding='utf-8'
                )
            # è®°å½•è¿™æ¡æ•°æ®å·²ç»è¢«å•ç‹¬ä¿å­˜è¿‡äº†ï¼Œé¿å…é‡å¤ä¿å­˜
            self._mark_record_saved(record)
        except Exception as e:
            print(f"âš ï¸ å•æ¡è®°å½•ä¿å­˜å¤±è´¥: {e}")
    
    def _mark_record_saved(self, record: Dict[str, Any]):
        """æ ‡è®°è®°å½•å·²ä¿å­˜ï¼Œåœ¨force_saveæ—¶è·³è¿‡"""
        if not hasattr(self, '_saved_records'):
            self._saved_records = set()
        # ä½¿ç”¨timestamp + usernameä½œä¸ºå”¯ä¸€æ ‡è¯†
        record_id = f"{record['timestamp']}_{record['username']}"
        self._saved_records.add(record_id)
    
    def _is_record_saved(self, record: Dict[str, Any]) -> bool:
        """æ£€æŸ¥è®°å½•æ˜¯å¦å·²ç»è¢«ä¿å­˜è¿‡"""
        if not hasattr(self, '_saved_records'):
            return False
        record_id = f"{record['timestamp']}_{record['username']}"
        return record_id in self._saved_records
    
    def force_save(self):
        """å¼ºåˆ¶ä¿å­˜ç¼“å†²åŒºæ‰€æœ‰æ•°æ®"""
        if self.buffer_df.empty:
            print("ðŸ“ ç¼“å†²åŒºä¸ºç©ºï¼Œæ— éœ€ä¿å­˜")
            return True
        
        # è¿‡æ»¤æŽ‰å·²ç»å•ç‹¬ä¿å­˜è¿‡çš„è®°å½•
        unsaved_records = []
        for _, row in self.buffer_df.iterrows():
            record = row.to_dict()
            if not self._is_record_saved(record):
                unsaved_records.append(record)
        
        if not unsaved_records:
            print("ðŸ“ ç¼“å†²åŒºä¸­æ‰€æœ‰è®°å½•å·²ä¿å­˜ï¼Œæ¸…ç©ºç¼“å†²åŒº")
            self.buffer_df = pd.DataFrame()
            return True
        
        try:
            # åªä¿å­˜æœªä¿å­˜çš„è®°å½•
            unsaved_df = pd.DataFrame(unsaved_records)
            with self.file_lock:  # filelockè‡ªåŠ¨å¤„ç†è·¨è¿›ç¨‹æ–‡ä»¶é”
                unsaved_df.to_csv(
                    self.csv_file,
                    mode='a',  # è¿½åŠ æ¨¡å¼ï¼Œæ°¸ä¸è¦†ç›–
                    header=not self.csv_file.exists(),  # æ–‡ä»¶ä¸å­˜åœ¨æ—¶å†™è¡¨å¤´
                    index=False,  # ä¸å†™è¡Œç´¢å¼•
                    encoding='utf-8'
                )
            
            count = len(unsaved_records)
            # æ¸…ç©ºç¼“å†²åŒº
            self.buffer_df = pd.DataFrame()
            
            if count > 0:
                print(f"ðŸ’¾ æˆåŠŸä¿å­˜ {count} æ¡æ–°è®°å½•åˆ° {self.csv_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_saved = 0
        if self.csv_file.exists():
            try:
                # è¯»å–å·²ä¿å­˜çš„è®°å½•æ•°
                df = pd.read_csv(self.csv_file)
                total_saved = len(df)
            except:
                total_saved = 0
        
        # è®¡ç®—çœŸæ­£æœªä¿å­˜çš„ç¼“å†²åŒºè®°å½•æ•°
        unsaved_buffer_count = 0
        if not self.buffer_df.empty:
            for _, row in self.buffer_df.iterrows():
                record = row.to_dict()
                if not self._is_record_saved(record):
                    unsaved_buffer_count += 1
        
        return {
            'file_path': str(self.csv_file),
            'buffer_count': unsaved_buffer_count,  # åªè®¡ç®—çœŸæ­£æœªä¿å­˜çš„
            'total_saved': total_saved,
            'batch_size': self.batch_size
        }
    
    def get_csv_filepath(self) -> Path:
        """Get the path to the CSV file being used"""
        return self.csv_file
    
    def cleanup(self):
        """Cleanup service resources and save any remaining buffer"""
        self.force_save()