"""
Persistence service for saving account registration results to CSV files.

Provides safe, reliable CSV persistence with:
- Pandas DataFrame for efficient CSV operations
- File locking to prevent concurrent access issues
- Signal handling for graceful shutdown on Ctrl-C
- Batch saving (configurable batch_size, default 5)
- Append-only operations to prevent data loss
"""

import atexit
import signal
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

import pandas as pd
from filelock import FileLock

from ..models.account import Account


class PersistenceService:
    """Service for persisting account registration results to CSV files"""
    
    def __init__(self, output_dir: str = ".", batch_size: int = 5):
        """
        Initialize persistence service
        
        Args:
            output_dir: Directory to save CSV files (default: current directory)
            batch_size: Number of results to buffer before auto-save (default: 5)
        """
        self.output_dir = Path(output_dir)
        self.batch_size = batch_size
        
        # Generate timestamp-based filename to avoid conflicts
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_id = timestamp
        self.csv_file = self.output_dir / f"registration_results_{timestamp}.csv"
        self.lock_file = self.output_dir / f"registration_results_{timestamp}.csv.lock"
        
        # ä½¿ç”¨pandas DataFrameä½œä¸ºå†…å­˜ç¼“å†²åŒº
        self.buffer_df = pd.DataFrame()
        
        # åˆ›å»ºæ–‡ä»¶é”
        self.file_lock = FileLock(self.lock_file)
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        self._setup_signal_handlers()
        
        # æ³¨å†Œç¨‹åºæ­£å¸¸é€€å‡ºæ—¶çš„æ¸…ç†
        atexit.register(self.force_save)
        
        print(f"ðŸ’¾ ç»“æžœå°†ä¿å­˜åˆ°: {self.csv_file}")
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def emergency_save(signum=None, frame=None):
            print(f"\nðŸš¨ æŽ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ç´§æ€¥ä¿å­˜...")
            success = self.force_save()
            if success:
                print("âœ… æ•°æ®ä¿å­˜å®Œæˆï¼Œç¨‹åºå®‰å…¨é€€å‡º")
            else:
                print("âš ï¸ ä¿å­˜å¯èƒ½ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶")
            sys.exit(0)
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, emergency_save)   # Ctrl-C
        signal.signal(signal.SIGTERM, emergency_save)  # ç¨‹åºç»ˆæ­¢
    
    def add_result(self, account: Account, duration: float, backend: str):
        """æ·»åŠ æ³¨å†Œç»“æžœåˆ°ç¼“å†²åŒº"""
        # åˆ›å»ºæ–°è®°å½•
        new_record = {
            'timestamp': datetime.now().isoformat(),
            'username': account.username,
            'password': account.password,
            'status': account.status.value,
            'notes': account.notes,
            'duration_seconds': round(duration, 2),
            'backend': backend,
            'session_id': self.session_id
        }
        
        # æ·»åŠ åˆ°DataFrameç¼“å†²åŒº
        new_df = pd.DataFrame([new_record])
        self.buffer_df = pd.concat([self.buffer_df, new_df], ignore_index=True)
        
        print(f"ðŸ“ ç¼“å†²åŒº: {len(self.buffer_df)}/{self.batch_size}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡ä¿å­˜
        if len(self.buffer_df) >= self.batch_size:
            self.force_save()
        else:
            # å¦‚æžœæ²¡æœ‰è¾¾åˆ°batch_sizeï¼Œç«‹å³ä¿å­˜å•æ¡è®°å½•é˜²æ­¢æ•°æ®ä¸¢å¤±
            self._save_single_record(new_record)
    
    def _save_single_record(self, record: Dict[str, Any]):
        """ç«‹å³ä¿å­˜å•æ¡è®°å½•ï¼ˆé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼‰"""
        try:
            single_df = pd.DataFrame([record])
            with self.file_lock:
                single_df.to_csv(
                    self.csv_file,
                    mode='a',
                    header=not self.csv_file.exists(),
                    index=False,
                    encoding='utf-8'
                )
        except Exception as e:
            print(f"âš ï¸ å•æ¡è®°å½•ä¿å­˜å¤±è´¥: {e}")
    
    def force_save(self):
        """å¼ºåˆ¶ä¿å­˜ç¼“å†²åŒºæ‰€æœ‰æ•°æ®"""
        if self.buffer_df.empty:
            print("ðŸ“ ç¼“å†²åŒºä¸ºç©ºï¼Œæ— éœ€ä¿å­˜")
            return True
        
        try:
            with self.file_lock:  # filelockè‡ªåŠ¨å¤„ç†è·¨è¿›ç¨‹æ–‡ä»¶é”
                self.buffer_df.to_csv(
                    self.csv_file,
                    mode='a',  # è¿½åŠ æ¨¡å¼ï¼Œæ°¸ä¸è¦†ç›–
                    header=not self.csv_file.exists(),  # æ–‡ä»¶ä¸å­˜åœ¨æ—¶å†™è¡¨å¤´
                    index=False,  # ä¸å†™è¡Œç´¢å¼•
                    encoding='utf-8'
                )
            
            count = len(self.buffer_df)
            # æ¸…ç©ºç¼“å†²åŒº
            self.buffer_df = pd.DataFrame()
            
            print(f"ðŸ’¾ æˆåŠŸä¿å­˜ {count} æ¡è®°å½•åˆ° {self.csv_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_saved = 0
        if self.csv_file.exists():
            try:
                # è¯»å–å·²ä¿å­˜çš„è®°å½•æ•°
                df = pd.read_csv(self.csv_file)
                total_saved = len(df)
            except:
                total_saved = 0
        
        return {
            'file_path': str(self.csv_file),
            'buffer_count': len(self.buffer_df),
            'total_saved': total_saved,
            'batch_size': self.batch_size
        }
    
    def get_csv_filepath(self) -> Path:
        """Get the path to the CSV file being used"""
        return self.csv_file
    
    def cleanup(self):
        """Cleanup service resources and save any remaining buffer"""
        self.force_save()